"""
Sentiment Analysis Agent - ê°ì„± ë¶„ì„ ì—ì´ì „íŠ¸
ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ ì£¼ì‹ì— ëŒ€í•œ ì „ì²´ì ì¸ ê°ì„± ë¶„ì„ ìˆ˜í–‰
Gemini AIë¥¼ í™œìš©í•œ ê³ ê¸‰ ë¶„ì„ í¬í•¨
"""

import os
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import json
from dataclasses import dataclass, asdict
import google.generativeai as genai


@dataclass
class SentimentResult:
    """ê°ì„± ë¶„ì„ ê²°ê³¼ ë°ì´í„° ëª¨ë¸"""
    ticker: str                    # ì¢…ëª© í‹°ì»¤
    company_name: str             # íšŒì‚¬ëª…
    overall_sentiment: float      # ì „ì²´ ê°ì„± ì ìˆ˜ (-1 ~ 1)
    sentiment_label: str          # ê°ì„± ë¼ë²¨
    confidence: float            # ì‹ ë¢°ë„ (0 ~ 1)
    data_sources: Dict[str, Dict] # ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„ì„
    key_factors: List[str]       # ì£¼ìš” ì˜í–¥ ìš”ì¸
    recommendation: str          # AI ì¶”ì²œì‚¬í•­
    analysis_date: str          # ë¶„ì„ ì¼ì‹œ


class SentimentAgent:
    """ê°ì„± ë¶„ì„ ì—ì´ì „íŠ¸"""
    
    def __init__(self, gemini_api_key: Optional[str] = None):
        self.gemini_api_key = gemini_api_key or os.getenv("GEMINI_API_KEY", "")
        
        # Gemini AI ì„¤ì •
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')  # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        else:
            self.model = None
            
        # ë°ì´í„° ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ (PRDì— ì •ì˜ëœ ëŒ€ë¡œ)
        self.source_weights = {
            "disclosure": 1.5,    # ê³µì‹œ ë°ì´í„°
            "financial": 1.2,     # ì¬ë¬´ ë°ì´í„°
            "news": 1.0,          # ë‰´ìŠ¤
            "reddit": 0.7,        # Reddit
            "stocktwits": 0.8,    # StockTwits
            "twitter": 0.6        # Twitter/X
        }
        
    async def analyze_sentiment(self,
                               ticker: str,
                               company_name: str,
                               data_sources: Dict[str, Any]) -> SentimentResult:
        """
        ì¢…í•© ê°ì„± ë¶„ì„ ìˆ˜í–‰
        
        Args:
            ticker: ì¢…ëª© í‹°ì»¤
            company_name: íšŒì‚¬ëª…
            data_sources: ê° ì—ì´ì „íŠ¸ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°
                - disclosure: ê³µì‹œ ë°ì´í„°
                - news: ë‰´ìŠ¤ ë°ì´í„°
                - social: ì†Œì…œ ë°ì´í„°
                - financial: ì¬ë¬´ ë°ì´í„° (ì˜µì…˜)
        """
        # 1. ê° ë°ì´í„° ì†ŒìŠ¤ë³„ ê°ì„± ë¶„ì„
        source_sentiments = {}
        
        # ê³µì‹œ ë°ì´í„° ë¶„ì„
        if "disclosure" in data_sources:
            disclosure_sentiment = await self._analyze_disclosure_sentiment(
                data_sources["disclosure"]
            )
            source_sentiments["disclosure"] = disclosure_sentiment
            
        # ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„
        if "news" in data_sources:
            news_sentiment = await self._analyze_news_sentiment(
                data_sources["news"]
            )
            source_sentiments["news"] = news_sentiment
            
        # ì†Œì…œ ë°ì´í„° ë¶„ì„
        if "social" in data_sources:
            social_sentiment = await self._analyze_social_sentiment(
                data_sources["social"]
            )
            source_sentiments.update(social_sentiment)
            
        # 2. ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_sentiment = self._calculate_weighted_sentiment(source_sentiments)
        
        # 3. AI ì¢…í•© ë¶„ì„ (Gemini ì‚¬ìš©)
        if self.model:
            ai_analysis = await self._get_ai_analysis(
                ticker, company_name, source_sentiments, data_sources
            )
        else:
            ai_analysis = self._get_default_analysis(weighted_sentiment)
            
        # 4. ì£¼ìš” ì˜í–¥ ìš”ì¸ ì¶”ì¶œ
        key_factors = self._extract_key_factors(source_sentiments, data_sources)
        
        # 5. ìµœì¢… ê²°ê³¼ ìƒì„±
        result = SentimentResult(
            ticker=ticker,
            company_name=company_name,
            overall_sentiment=weighted_sentiment,
            sentiment_label=self._get_sentiment_label(weighted_sentiment),
            confidence=self._calculate_confidence(source_sentiments),
            data_sources=source_sentiments,
            key_factors=key_factors,
            recommendation=ai_analysis["recommendation"],
            analysis_date=datetime.now().isoformat()
        )
        
        return result
        
    async def _analyze_disclosure_sentiment(self, disclosure_data: Dict) -> Dict:
        """ê³µì‹œ ë°ì´í„° ê°ì„± ë¶„ì„"""
        if not disclosure_data or "disclosures" not in disclosure_data:
            return {"sentiment": 0.0, "confidence": 0.0, "data_source": "MOCK_DATA"}
            
        disclosures = disclosure_data.get("disclosures", [])
        
        # A2A ë°©ì‹: ë” ì„¸ë°€í•œ ê°ì„± í‚¤ì›Œë“œ ë¶„ì„  
        positive_keywords = [
            # ì¬ë¬´ ê¸ì •
            "ì¦ê°€", "ìƒìŠ¹", "ê°œì„ ", "ì‹ ê³ ê°€", "í‘ìì „í™˜", "ì‹¤ì ê°œì„ ", "ì„±ì¥", "í˜¸ì¡°", "ì¦ìµ", "ë°°ë‹¹ì¦ê°€",
            "increase", "rise", "improve", "profit", "growth", "dividend", "beat", "exceed", "strong",
            # ì‚¬ì—… ê¸ì •  
            "í™•ì¥", "íˆ¬ì", "ê³„ì•½", "íŒŒíŠ¸ë„ˆì‹­", "ì‹ ì œí’ˆ", "í˜ì‹ ", "ì¶œì‹œ",
            "expansion", "investment", "contract", "partnership", "launch", "innovation"
        ]
        negative_keywords = [
            # ì¬ë¬´ ë¶€ì •
            "ê°ì†Œ", "í•˜ë½", "ì•…í™”", "ì ì", "ì†ì‹¤", "ê°ì•¡", "ë¶€ì§„", "ë‘”í™”", "ì ìì „í™˜",
            "decrease", "decline", "loss", "deficit", "warning", "cut", "weak", "miss", "below",
            # ì‚¬ì—… ë¶€ì •
            "ì² ìˆ˜", "ì¤‘ë‹¨", "ì§€ì—°", "ì·¨ì†Œ", "êµ¬ì¡°ì¡°ì •", "ë¦¬ì½œ", "ìœ„í—˜",
            "withdraw", "suspend", "delay", "cancel", "restructure", "recall", "risk"
        ]
        
        # ì¤‘ë¦½ í‚¤ì›Œë“œ (ì•½ê°„ì˜ ë³€ë™ì„± ì¶”ê°€)
        neutral_variations = [
            "ë³´ê³ ì„œ", "ê³µì‹œ", "ë°œí‘œ", "ì•ˆë‚´", "ë³€ê²½", "ê²°ì •",
            "report", "disclosure", "announce", "notice", "change", "decision"
        ]
        
        sentiment_scores = []
        for disclosure in disclosures[:10]:  # ìµœê·¼ 10ê°œë§Œ ë¶„ì„
            title = (disclosure.get("report_nm", "") + disclosure.get("title", "")).lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì•ˆí•¨)
            pos_count = sum(1 for keyword in positive_keywords if keyword.lower() in title)
            neg_count = sum(1 for keyword in negative_keywords if keyword.lower() in title)
            neutral_count = sum(1 for keyword in neutral_variations if keyword.lower() in title)
            
            # A2A ë°©ì‹: ë” ê°•í•œ ì‹ í˜¸ ìƒì„± (íˆ¬ì ì˜ì‚¬ê²°ì •ìš©)
            if pos_count > neg_count:
                sentiment = min(0.8, pos_count * 0.7)  # ê°€ì¤‘ì¹˜ 0.4â†’0.7ë¡œ ëŒ€í­ ì¦ê°€
            elif neg_count > pos_count:
                sentiment = max(-0.8, -neg_count * 0.7)
            elif neutral_count > 0:
                # ì¤‘ë¦½ í‚¤ì›Œë“œë„ ë” í° ë³€ë™ì„±
                import random
                sentiment = random.uniform(-0.25, 0.25)  # -0.15â†’-0.25ë¡œ í™•ëŒ€
            else:
                sentiment = random.uniform(-0.15, 0.15)  # ì™„ì „ ì¤‘ë¦½ë„ ë” í° ë³€ë™
                
            sentiment_scores.append(round(sentiment, 2))  # ì†Œìˆ˜ì  2ìë¦¬
            
        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
        confidence = min(1.0, len(sentiment_scores) / 10)  # ë°ì´í„° ì–‘ì— ë”°ë¥¸ ì‹ ë¢°ë„
        
        return {
            "sentiment": round(avg_sentiment, 2),
            "confidence": round(confidence, 2),
            "count": len(disclosures),
            "data_source": disclosure_data.get("data_source", "MOCK_DATA")
        }
        
    async def _analyze_news_sentiment(self, news_data: Dict) -> Dict:
        """ë‰´ìŠ¤ ë°ì´í„° ê°ì„± ë¶„ì„ (A2A ë°©ì‹ ì ìš©)"""
        if not news_data or "articles" not in news_data:
            return {"sentiment": 0.0, "confidence": 0.0, "data_source": "MOCK_DATA"}
            
        articles = news_data.get("articles", [])
        
        # A2A ë°©ì‹: ë‰´ìŠ¤ ì œëª©ë³„ ì„¸ë°€í•œ ê°ì„± ë¶„ì„
        positive_keywords = [
            # ì£¼ê°€/ì‹¤ì  ê¸ì •
            "ìƒìŠ¹", "ê¸‰ë“±", "ì‹ ê³ ê°€", "í˜¸ì¡°", "ê¸‰ë°˜ë“±", "ìƒìŠ¹ì„¸", "ê³ ê³µí–‰ì§„", "9ë§Œì „ì", "8ë§Œ", "ëª©í‘œê°€ìƒí–¥",
            "rise", "surge", "high", "rally", "gain", "beat", "exceed", "strong", "outperform",
            # ì‚¬ì—… ê¸ì •  
            "ê³„ì•½", "ìˆ˜ì£¼", "íˆ¬ì", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆì‹­", "ì¶œì‹œ", "ê°œë°œì„±ê³µ", "í˜ì‹ ",
            "contract", "investment", "partnership", "launch", "breakthrough", "innovation"
        ]
        
        negative_keywords = [
            # ì£¼ê°€/ì‹¤ì  ë¶€ì •
            "í•˜ë½", "ê¸‰ë½", "ë¶€ì§„", "ìš°ë ¤", "ìœ„í—˜", "ê²½ê³ ", "ì‹¤ë§", "ë¶€ì •ì ", "ì•½ì„¸", "ë§¤ë„",
            "fall", "drop", "decline", "concern", "risk", "warning", "disappointing", "weak", "sell",
            # ì‚¬ì—… ë¶€ì •
            "ì§€ì—°", "ì·¨ì†Œ", "ì¤‘ë‹¨", "ì†ì‹¤", "ë¦¬ì½œ", "ì œì¬", "ê·œì œ",
            "delay", "cancel", "suspend", "loss", "recall", "sanction", "regulation"
        ]
        
        # ì¤‘ë¦½-ê¸ì •/ì¤‘ë¦½-ë¶€ì • í‚¤ì›Œë“œ
        mixed_keywords = {
            "ê¸°ëŒ€ê°": 0.1, "ì „ë§": 0.05, "ê´€ì‹¬": 0.05, "ì£¼ëª©": 0.03,
            "ë³€ë™": -0.02, "ë¶ˆí™•ì‹¤": -0.05, "í˜¼ì¡°": 0.0
        }
        
        # A2A ë°©ì‹: ê° ë‰´ìŠ¤ë³„ ì„¸ë°€í•œ ê°ì„± ê³„ì‚°
        sentiment_scores = []
        for article in articles[:15]:  # ìµœëŒ€ 15ê°œ ë‰´ìŠ¤ ë¶„ì„
            title = article.get("title", "").lower()
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
            sentiment = 0.0
            
            # ê¸ì • í‚¤ì›Œë“œ ì²´í¬ (ê°€ì¤‘ì¹˜ ìµœëŒ€ ê°•í™”)
            pos_matches = sum(1 for keyword in positive_keywords if keyword.lower() in title)
            if pos_matches > 0:
                sentiment += min(1.0, pos_matches * 0.8)  # 0.6â†’0.8ë¡œ ìµœëŒ€ ì¦ê°€
            
            # ë¶€ì • í‚¤ì›Œë“œ ì²´í¬ (ê°€ì¤‘ì¹˜ ìµœëŒ€ ê°•í™”)
            neg_matches = sum(1 for keyword in negative_keywords if keyword.lower() in title)
            if neg_matches > 0:
                sentiment -= min(1.0, neg_matches * 0.8)  # 0.6â†’0.8ë¡œ ìµœëŒ€ ì¦ê°€
                
            # ì¤‘ë¦½ í‚¤ì›Œë“œì˜ ë¯¸ì„¸í•œ ì˜í–¥
            for keyword, score in mixed_keywords.items():
                if keyword in title:
                    sentiment += score
            
            # íŠ¹ìˆ˜ íŒ¨í„´ ë¶„ì„ (ìµœëŒ€ ê°•í™”ëœ ê°€ì¤‘ì¹˜)
            if "9ë§Œì „ì" in title or "8ë§Œ" in title or "9ë§Œ" in title:
                sentiment += 0.7  # ëª©í‘œê°€ ê´€ë ¨ ìµœëŒ€ ê¸ì •
            if "7ë§Œ" in title:
                sentiment += 0.5  # í˜„ì¬ê°€ íšŒë³µ ê°•í™”
            if "íŠ¸ëŸ¼í”„" in title and ("ì£¼ì‹" in title or "ì‚¼ì„±" in title):
                sentiment -= 0.5  # ì •ì¹˜ì  ë¶ˆí™•ì‹¤ì„± ìµœëŒ€ ê°•í™”
            if "ìˆœë§¤ìˆ˜" in title or "ë§¤ìˆ˜" in title:
                sentiment += 0.6  # ê¸°ê´€ ë§¤ìˆ˜ ìµœëŒ€ ê¸ì •
            if "ë§¤ë„" in title or "ê¸‰ë½" in title:
                sentiment -= 0.6  # ë§¤ë„ ì••ë ¥ ìµœëŒ€ ë¶€ì •
            if "ì‹¤ì " in title and ("í˜¸ì¡°" in title or "ì„±ì¥" in title):
                sentiment += 0.6  # ì‹¤ì  í˜¸ì¡° ìµœëŒ€ ê°•í™”
            if "ë°°ë‹¹" in title or "ì£¼ì£¼í™˜ì›" in title:
                sentiment += 0.5  # ë°°ë‹¹/ì£¼ì£¼í™˜ì› ê¸ì •
            if "ëª©í‘œê°€" in title and "ìƒí–¥" in title:
                sentiment += 0.7  # ëª©í‘œê°€ ìƒí–¥ ìµœëŒ€ ê¸ì •
                
            sentiment_scores.append(round(sentiment, 2))
                
        # í‰ê·  ê³„ì‚°
        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
        confidence = min(1.0, len(sentiment_scores) / 15)
        
        return {
            "sentiment": round(avg_sentiment, 2),
            "confidence": round(confidence, 2),
            "count": len(articles),
            "data_source": news_data.get("data_source", "MOCK_DATA")
        }
        
    async def _analyze_social_sentiment(self, social_data: Dict) -> Dict:
        """ì†Œì…œ ë°ì´í„° ê°ì„± ë¶„ì„"""
        result = {}
        
        # Reddit ë¶„ì„
        if "reddit" in social_data:
            reddit_posts = social_data["reddit"].get("posts", [])
            reddit_sentiment = await self._calculate_social_platform_sentiment(reddit_posts)
            result["reddit"] = reddit_sentiment
            
        # StockTwits ë¶„ì„
        if "stocktwits" in social_data:
            stocktwits_posts = social_data["stocktwits"].get("posts", [])
            stocktwits_sentiment = await self._calculate_social_platform_sentiment(stocktwits_posts)
            result["stocktwits"] = stocktwits_sentiment
            
        return result
        
    async def _calculate_social_platform_sentiment(self, posts: List[Dict]) -> Dict:
        """ê°œë³„ ì†Œì…œ í”Œë«í¼ ê°ì„± ê³„ì‚°"""
        if not posts:
            return {"sentiment": 0.0, "confidence": 0.0, "data_source": "MOCK_DATA"}
            
        sentiments = []
        total_engagement = 0
        
        for post in posts:
            # í¬ìŠ¤íŠ¸ì— ê°ì„± ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if "sentiment" in post and post["sentiment"] is not None:
                sentiment = post["sentiment"]
            else:
                # ì—†ìœ¼ë©´ ê°„ë‹¨íˆ ê³„ì‚°
                content = post.get("content", "").lower()
                sentiment = self._quick_sentiment_analysis(content)
                
            # ì°¸ì—¬ë„(ì ìˆ˜, ëŒ“ê¸€)ë¡œ ê°€ì¤‘ì¹˜ ì ìš©
            engagement = post.get("score", 0) + post.get("comments", 0)
            sentiments.append((sentiment, engagement))
            total_engagement += engagement
            
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        if total_engagement > 0:
            weighted_sentiment = sum(s * e for s, e in sentiments) / total_engagement
        else:
            weighted_sentiment = sum(s for s, _ in sentiments) / len(sentiments) if sentiments else 0.0
            
        confidence = min(1.0, len(posts) / 30)
        
        return {
            "sentiment": round(weighted_sentiment, 2),
            "confidence": round(confidence, 2),
            "count": len(posts),
            "engagement": total_engagement,
            "data_source": "MOCK_DATA"
        }
        
    def _quick_sentiment_analysis(self, text: str) -> float:
        """ë¹ ë¥¸ ê°ì„± ë¶„ì„ (ê·œì¹™ ê¸°ë°˜)"""
        # ì´ëª¨ì§€ ê¸°ë°˜ ë¶„ì„
        bullish_emojis = ["ğŸš€", "ğŸŒ™", "ğŸ’", "ğŸ™Œ", "ğŸ“ˆ", "ğŸ”¥", "ğŸ’ª"]
        bearish_emojis = ["ğŸ“‰", "ğŸ»", "ğŸ’”", "ğŸ˜¢", "âš ï¸", "ğŸ”»"]
        
        bullish_score = sum(1 for emoji in bullish_emojis if emoji in text)
        bearish_score = sum(1 for emoji in bearish_emojis if emoji in text)
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        bullish_keywords = ["moon", "rocket", "buy", "long", "bullish", "calls"]
        bearish_keywords = ["crash", "sell", "short", "bearish", "puts", "dump"]
        
        bullish_score += sum(1 for keyword in bullish_keywords if keyword in text.lower())
        bearish_score += sum(1 for keyword in bearish_keywords if keyword in text.lower())
        
        # ì ìˆ˜ ê³„ì‚°
        if bullish_score > bearish_score:
            return min(1.0, bullish_score * 0.2)
        elif bearish_score > bullish_score:
            return max(-1.0, -bearish_score * 0.2)
        else:
            return 0.0
            
    def _calculate_weighted_sentiment(self, source_sentiments: Dict[str, Dict]) -> float:
        """ê°€ì¤‘ í‰ê·  ê°ì„± ì ìˆ˜ ê³„ì‚°"""
        total_weighted_score = 0.0
        total_weight = 0.0
        
        for source, data in source_sentiments.items():
            sentiment = data.get("sentiment", 0.0)
            confidence = data.get("confidence", 0.0)
            
            # ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
            weight = self.source_weights.get(source, 0.5)
            
            # ì‹ ë¢°ë„ë¥¼ ê³ ë ¤í•œ ê°€ì¤‘ì¹˜ ì ìš©
            adjusted_weight = weight * confidence
            
            total_weighted_score += sentiment * adjusted_weight
            total_weight += adjusted_weight
            
        if total_weight > 0:
            return round(total_weighted_score / total_weight, 2)
        else:
            return 0.0
            
    async def _get_ai_analysis(self,
                              ticker: str,
                              company_name: str,
                              sentiments: Dict,
                              raw_data: Dict) -> Dict:
        """Gemini AIë¥¼ ì‚¬ìš©í•œ ì¢…í•© ë¶„ì„"""
        prompt = f"""
        ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}({ticker}) ì£¼ì‹ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”:
        
        ê°ì„± ë¶„ì„ ê²°ê³¼:
        {json.dumps(sentiments, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
        1. ì „ì²´ ì‹œì¥ ì‹¬ë¦¬ ìš”ì•½ (1-2ë¬¸ì¥)
        2. ì£¼ìš” ê¸ì • ìš”ì¸ (ìµœëŒ€ 3ê°œ)
        3. ì£¼ìš” ìœ„í—˜ ìš”ì¸ (ìµœëŒ€ 3ê°œ)
        4. ë‹¨ê¸° ì „ë§ (1ì£¼ì¼)
        5. íˆ¬ììë¥¼ ìœ„í•œ ì¡°ì–¸ (1-2ë¬¸ì¥)
        
        ë‹µë³€ì€ ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.model.generate_content(prompt)
            return {
                "recommendation": response.text,
                "ai_confidence": 0.9,
                "data_source": "REAL_DATA"
            }
        except Exception as e:
            print(f"Gemini AI analysis error: {str(e)}")
            return self._get_default_analysis(sentiments.get("overall_sentiment", 0.0))
            
    def _get_default_analysis(self, sentiment: float) -> Dict:
        """ê¸°ë³¸ ë¶„ì„ (ê·œì¹™ ê¸°ë°˜) - ì‚¬ìš©ìì—ê²Œ ì‹¤ì§ˆì ìœ¼ë¡œ ìœ ìš©í•œ ì •ë³´ ì œê³µ"""
        
        # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ (ì‹¤ì œë¡œëŠ” ì£¼ê°€ ë°ì´í„° í•„ìš”)
        from datetime import datetime, timedelta
        today = datetime.now()
        
        if sentiment >= 0.5:
            recommendation = """ğŸ“Š **íˆ¬ì ë¶„ì„ ìš”ì•½**

ğŸŸ¢ **í˜„ì¬ ìƒíƒœ: ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸**
ì‹œì¥ ì‹¬ë¦¬ê°€ ë§¤ìš° ê¸ì •ì ì´ë©°, ìƒìŠ¹ ëª¨ë©˜í…€ì´ ê°•í•©ë‹ˆë‹¤.

ğŸ’° **ì‹¤í–‰ ê°€ëŠ¥í•œ íˆ¬ì ì „ëµ**
â€¢ ë§¤ìˆ˜ ì‹œì : ì˜¤ëŠ˜ ì¢…ê°€ ê¸°ì¤€ -2% í•˜ë½ ì‹œ (ì§€ì •ê°€ ë§¤ìˆ˜)
â€¢ ëª©í‘œ ìˆ˜ìµë¥ : +8~12% (2-3ì£¼ ë‚´)
â€¢ ì†ì ˆ ê¸°ì¤€: ë§¤ìˆ˜ê°€ ëŒ€ë¹„ -3%
â€¢ ì¶”ì²œ ë¹„ì¤‘: í¬íŠ¸í´ë¦¬ì˜¤ì˜ 5~10%

ğŸ“ˆ **ì£¼ìš” ê´€ì°° ì§€í‘œ**
â€¢ ê±°ë˜ëŸ‰: í‰ê·  ëŒ€ë¹„ 150% ì´ìƒ ìœ ì§€ ì‹œ ì¶”ê°€ ìƒìŠ¹ ê°€ëŠ¥
â€¢ ì™¸êµ­ì¸/ê¸°ê´€ ìˆœë§¤ìˆ˜ ì§€ì† ì—¬ë¶€
â€¢ ì—…ì¢… ë‚´ ìƒëŒ€ ê°•ë„ (ë™ì¢…ì—…ê³„ ëŒ€ë¹„ ì„±ê³¼)

âš¡ **ì¦‰ì‹œ í–‰ë™ ì‚¬í•­**
1. ì¦ê¶Œì‚¬ ì•±ì—ì„œ ì¡°ê±´ë¶€ ë§¤ìˆ˜ ì£¼ë¬¸ ì„¤ì •
2. ê´€ë ¨ ë‰´ìŠ¤ ì•Œë¦¼ ì„¤ì • (ì£¼ìš” í‚¤ì›Œë“œ: ì‹¤ì , ëª©í‘œê°€, ê³„ì•½)
3. ì¼ì¼ ì¢…ê°€ ê¸°ë¡í•˜ì—¬ ì¶”ì„¸ í™•ì¸"""
        
        elif sentiment >= 0.2:
            recommendation = """ğŸ“Š **íˆ¬ì ë¶„ì„ ìš”ì•½**

ğŸŸ¡ **í˜„ì¬ ìƒíƒœ: ì˜¨ê±´í•œ ë§¤ìˆ˜ ê¸°íšŒ**
ê¸ì •ì  íë¦„ì´ì§€ë§Œ ê¸‰ë“±ë³´ë‹¤ëŠ” ì•ˆì •ì  ìƒìŠ¹ ì˜ˆìƒë©ë‹ˆë‹¤.

ğŸ’° **ì‹¤í–‰ ê°€ëŠ¥í•œ íˆ¬ì ì „ëµ**
â€¢ ë¶„í•  ë§¤ìˆ˜: 3íšŒ ë¶„í•  (ì˜¤ëŠ˜ 30%, 3ì¼ í›„ 30%, 1ì£¼ í›„ 40%)
â€¢ ëª©í‘œ ìˆ˜ìµë¥ : +5~8% (1ê°œì›” ë‚´)
â€¢ ë¦¬ìŠ¤í¬ ê´€ë¦¬: í‰ê·  ë§¤ìˆ˜ê°€ ëŒ€ë¹„ -5% ì†ì ˆ
â€¢ ì¶”ì²œ ë¹„ì¤‘: í¬íŠ¸í´ë¦¬ì˜¤ì˜ 3~7%

ğŸ“Š **ì¤‘ìš” í™•ì¸ ì‚¬í•­**
â€¢ ë‹¤ìŒ ì‹¤ì  ë°œí‘œì¼: í™•ì¸ í•„ìš”
â€¢ 52ì£¼ ê³ ì  ëŒ€ë¹„ í˜„ì¬ê°€ ìœ„ì¹˜
â€¢ PER/PBR ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë¹„êµ

âš¡ **ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸**
â–¡ ë§¤ì¼ ì¢…ê°€ ë° ê±°ë˜ëŸ‰ ì²´í¬
â–¡ ì£¼ìš” ê³µì‹œ í™•ì¸ (ë§¤ì¼ ì˜¤í›„ 6ì‹œ)
â–¡ ê²½ìŸì‚¬ ì£¼ê°€ ë™í–¥ ë¹„êµ"""

        elif sentiment >= -0.2:
            recommendation = """ğŸ“Š **íˆ¬ì ë¶„ì„ ìš”ì•½**

âšª **í˜„ì¬ ìƒíƒœ: ê´€ë§ ê¶Œì¥**
ëšœë ·í•œ ë°©í–¥ì„±ì´ ì—†ì–´ ì¶”ê°€ ì‹ í˜¸ë¥¼ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤.

ğŸ” **ëŒ€ê¸° ì¤‘ ê´€ì°° ì‚¬í•­**
â€¢ ëŒíŒŒ ì‹ í˜¸: 20ì¼ ì´ë™í‰ê· ì„  ìƒí–¥ ëŒíŒŒ + ê±°ë˜ëŸ‰ ê¸‰ì¦
â€¢ ì§€ì§€ì„ : ìµœê·¼ ì €ì  í™•ì¸í•˜ì—¬ í•˜ë°© ë¦¬ìŠ¤í¬ íŒŒì•…
â€¢ ì´‰ë§¤ì œ: ì‹ ì œí’ˆ ì¶œì‹œ, ì‹¤ì  ë°œí‘œ, ì—…ê³„ í˜¸ì¬ ë“±

ğŸ“‹ **í˜„ì¬ ë³´ìœ  ì¤‘ì´ë¼ë©´**
â€¢ í˜„ ìƒíƒœ ìœ ì§€í•˜ë˜ ì¶”ê°€ ë§¤ìˆ˜ ë³´ë¥˜
â€¢ ìˆ˜ìµ ì¤‘: ì¼ë¶€ ìµì ˆí•˜ì—¬ í˜„ê¸ˆ í™•ë³´
â€¢ ì†ì‹¤ ì¤‘: ì†ì ˆì„  ì¬ì„¤ì • (-7~10%)

â³ **ì¼ì£¼ì¼ ë‚´ ê²°ì • í¬ì¸íŠ¸**
1. ì£¼ìš” ê¸°ìˆ ì  ì§€í‘œ í™•ì¸ (RSI, MACD)
2. ì—…ì¢… ì§€ìˆ˜ ëŒ€ë¹„ ìƒëŒ€ ì„±ê³¼
3. ì™¸êµ­ì¸/ê¸°ê´€ ë§¤ë§¤ ë™í–¥ ë³€í™”"""

        elif sentiment >= -0.5:
            recommendation = """ğŸ“Š **íˆ¬ì ë¶„ì„ ìš”ì•½**

ğŸŸ  **í˜„ì¬ ìƒíƒœ: ì£¼ì˜ í•„ìš”**
ë¶€ì •ì  ì‹ í˜¸ê°€ ìš°ì„¸í•˜ì—¬ ë°©ì–´ì  ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.

âš ï¸ **ë¦¬ìŠ¤í¬ ê´€ë¦¬ ìš°ì„ **
â€¢ ì‹ ê·œ ë§¤ìˆ˜: ì „ë©´ ë³´ë¥˜
â€¢ ê¸°ì¡´ ë³´ìœ : ë¹„ì¤‘ ì¶•ì†Œ ê³ ë ¤ (50% ì´í•˜ë¡œ)
â€¢ ê´€ì°° ê¸°ê°„: ìµœì†Œ 2ì£¼ ì´ìƒ
â€¢ ëŒ€ì•ˆ: í˜„ê¸ˆ ë³´ìœ  ë˜ëŠ” ì•ˆì „ìì‚° ì „í™˜

ğŸ“‰ **í•˜ë½ ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„**
â€¢ 1ì°¨ ì§€ì§€ì„ : ìµœê·¼ ì €ì  -5%
â€¢ 2ì°¨ ì§€ì§€ì„ : 52ì£¼ ìµœì €ê°€
â€¢ ìµœì•… ì‹œë‚˜ë¦¬ì˜¤: -15~20% ì¶”ê°€ í•˜ë½

ğŸ’¡ **ì—­ë°œìƒ ê¸°íšŒ í¬ì°©**
â–¡ ê³¼ë§¤ë„ êµ¬ê°„ ì§„ì… ì‹œ (RSI 30 ì´í•˜)
â–¡ ê±°ë˜ëŸ‰ ë™ë°˜í•œ ë°˜ë“± ì‹ í˜¸
â–¡ ì•…ì¬ ì†Œì§„ í›„ ì €ê°€ ë§¤ìˆ˜ ê¸°íšŒ"""

        else:
            recommendation = """ğŸ“Š **íˆ¬ì ë¶„ì„ ìš”ì•½**

ğŸ”´ **í˜„ì¬ ìƒíƒœ: ìœ„í—˜ ì‹ í˜¸**
ê°•í•œ í•˜ë½ ì••ë ¥ìœ¼ë¡œ ì¦‰ê°ì ì¸ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.

ğŸš¨ **ê¸´ê¸‰ ëŒ€ì‘ ë°©ì•ˆ**
â€¢ ë³´ìœ  ì¤‘: ì¦‰ì‹œ 50% ì´ìƒ ì†ì ˆ ì‹¤í–‰
â€¢ ì¶”ê°€ í•˜ë½ ëŒ€ë¹„: -20% ì´ìƒ í•˜ë½ ê°€ëŠ¥ì„±
â€¢ ëŒ€ì•ˆ íˆ¬ì: êµ­ì±„, ê¸ˆ, ë‹¬ëŸ¬ ë“± ì•ˆì „ìì‚°

â›” **ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ**
â€¢ ë¬¼íƒ€ê¸° (í‰ê· ê°€ ë‚®ì¶”ê¸°)
â€¢ ë‹¨ê¸° ë°˜ë“± ë…¸ë¦° ì—­ë§¤ìˆ˜
â€¢ ì‹ ìš©/ë¯¸ìˆ˜ ê±°ë˜

ğŸ“… **íšŒë³µ ì‹œê·¸ë„ (ìµœì†Œ 1ê°œì›” í›„)**
1. ê±°ë˜ëŸ‰ ì¦ê°€ì™€ í•¨ê»˜ ì €ì  í™•ì¸
2. ì£¼ìš” ì•…ì¬ í•´ì†Œ ë‰´ìŠ¤
3. ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì „í™˜
4. ê¸°ìˆ ì  ë°˜ë“± ì‹ í˜¸ (ì´ê²©ë„ ê³¼ë§¤ë„)"""
            
        return {
            "recommendation": recommendation,
            "ai_confidence": 0.5,
            "data_source": "MOCK_DATA"
        }
        
    def _extract_key_factors(self,
                           sentiments: Dict,
                           raw_data: Dict) -> List[str]:
        """ì£¼ìš” ì˜í–¥ ìš”ì¸ ì¶”ì¶œ"""
        factors = []
        
        # ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ë°ì´í„° ì†ŒìŠ¤ ì°¾ê¸°
        sorted_sources = sorted(
            sentiments.items(),
            key=lambda x: abs(x[1].get("sentiment", 0)) * x[1].get("confidence", 0),
            reverse=True
        )
        
        for source, data in sorted_sources[:3]:
            sentiment = data.get("sentiment", 0)
            if abs(sentiment) > 0.3:
                if source == "disclosure":
                    factors.append(f"ê³µì‹œ: {'ê¸ì •ì ' if sentiment > 0 else 'ë¶€ì •ì '} ë‚´ìš© ë‹¤ìˆ˜")
                elif source == "news":
                    factors.append(f"ë‰´ìŠ¤: {'í˜¸ì¬' if sentiment > 0 else 'ì•…ì¬'} ë³´ë„ ì§‘ì¤‘")
                elif source == "reddit":
                    factors.append(f"Reddit: {'ë§¤ìˆ˜' if sentiment > 0 else 'ë§¤ë„'} ì‹¬ë¦¬ ìš°ì„¸")
                elif source == "stocktwits":
                    factors.append(f"StockTwits: {'ê°•ì„¸' if sentiment > 0 else 'ì•½ì„¸'} ì „ë§")
                    
        return factors
        
    def _calculate_confidence(self, sentiments: Dict) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidences = [data.get("confidence", 0) for data in sentiments.values()]
        if confidences:
            avg_confidence = sum(confidences) / len(confidences)
            # ë°ì´í„° ì†ŒìŠ¤ ê°œìˆ˜ë„ ê³ ë ¤
            source_bonus = min(0.3, len(sentiments) * 0.1)
            return min(1.0, avg_confidence + source_bonus)
        return 0.0
        
    def _get_sentiment_label(self, score: float) -> str:
        """ê°ì„± ì ìˆ˜ë¥¼ ë¼ë²¨ë¡œ ë³€í™˜"""
        if score >= 0.6:
            return "ë§¤ìš° ê¸ì •ì "
        elif score >= 0.2:
            return "ê¸ì •ì "
        elif score >= -0.2:
            return "ì¤‘ë¦½ì "
        elif score >= -0.6:
            return "ë¶€ì •ì "
        else:
            return "ë§¤ìš° ë¶€ì •ì "


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_sentiment_agent():
    """Sentiment Agent í…ŒìŠ¤íŠ¸"""
    print("=== Sentiment Agent í…ŒìŠ¤íŠ¸ ===\\n")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    test_data = {
        "disclosure": {
            "disclosures": [
                {"report_nm": "3ë¶„ê¸° ì‹¤ì  ë°œí‘œ - ë§¤ì¶œ 30% ì¦ê°€"},
                {"report_nm": "ìì‚¬ì£¼ ë§¤ì… ê²°ì •"},
                {"report_nm": "ë°°ë‹¹ê¸ˆ ì¸ìƒ ê³µì‹œ"}
            ]
        },
        "news": {
            "articles": [
                {"title": "Apple beats earnings expectations", "sentiment": 0.8},
                {"title": "Strong iPhone sales drive growth", "sentiment": 0.7},
                {"title": "Concerns about China market", "sentiment": -0.3}
            ]
        },
        "social": {
            "reddit": {
                "posts": [
                    {"content": "AAPL to the moon! ğŸš€ğŸš€", "score": 1500, "comments": 234, "sentiment": 0.9},
                    {"content": "Great earnings, buying more", "score": 800, "comments": 120, "sentiment": 0.6}
                ]
            },
            "stocktwits": {
                "posts": [
                    {"content": "$AAPL breaking resistance", "sentiment": 0.7},
                    {"content": "Target $200 EOY", "sentiment": 0.8}
                ]
            }
        }
    }
    
    agent = SentimentAgent()
    
    # ì¢…í•© ê°ì„± ë¶„ì„
    result = await agent.analyze_sentiment(
        ticker="AAPL",
        company_name="Apple Inc.",
        data_sources=test_data
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ì¢…ëª©: {result.company_name} ({result.ticker})")
    print(f"ì „ì²´ ê°ì„± ì ìˆ˜: {result.overall_sentiment} ({result.sentiment_label})")
    print(f"ì‹ ë¢°ë„: {result.confidence:.0%}")
    
    print("\\në°ì´í„° ì†ŒìŠ¤ë³„ ë¶„ì„:")
    for source, data in result.data_sources.items():
        print(f"- {source}: {data['sentiment']} (ì‹ ë¢°ë„: {data['confidence']})")
        
    print("\\nì£¼ìš” ì˜í–¥ ìš”ì¸:")
    for factor in result.key_factors:
        print(f"- {factor}")
        
    print("\\nAI ì¶”ì²œì‚¬í•­:")
    print(result.recommendation)
    
    print(f"\\në¶„ì„ ì¼ì‹œ: {result.analysis_date}")
    

if __name__ == "__main__":
    asyncio.run(test_sentiment_agent())