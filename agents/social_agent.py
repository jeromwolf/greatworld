"""
Social Agent - SNS ë°ì´í„° ìˆ˜ì§‘ ì—ì´ì „íŠ¸
Reddit, X(Twitter), StockTwits ë“±ì—ì„œ íˆ¬ìì ì‹¬ë¦¬ ë°ì´í„° ìˆ˜ì§‘
"""

import os
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json
from dataclasses import dataclass, asdict
import re


@dataclass
class SocialPost:
    """ì†Œì…œ ë¯¸ë””ì–´ í¬ìŠ¤íŠ¸ ë°ì´í„° ëª¨ë¸"""
    content: str            # ë‚´ìš©
    author: str            # ì‘ì„±ì
    platform: str          # í”Œë«í¼ (reddit, twitter, stocktwits)
    created_at: str        # ì‘ì„±ì¼ì‹œ
    url: str              # URL
    score: int = 0        # ì ìˆ˜/ì¢‹ì•„ìš”
    comments: int = 0     # ëŒ“ê¸€ ìˆ˜
    sentiment: Optional[float] = None  # ê°ì„± ì ìˆ˜


class SocialAgent:
    """SNS ë°ì´í„° ìˆ˜ì§‘ ì—ì´ì „íŠ¸"""
    
    def __init__(self, 
                 reddit_client_id: Optional[str] = None,
                 reddit_client_secret: Optional[str] = None):
        # Reddit API ì„¤ì •
        self.reddit_client_id = reddit_client_id or os.getenv("REDDIT_CLIENT_ID", "")
        self.reddit_client_secret = reddit_client_secret or os.getenv("REDDIT_CLIENT_SECRET", "")
        self.reddit_base_url = "https://oauth.reddit.com"
        
        self.session = None
        self.reddit_token = None
        
        # í”Œë«í¼ë³„ ê°€ì¤‘ì¹˜
        self.platform_weights = {
            "reddit_wsb": 0.8,      # r/wallstreetbets
            "reddit_stocks": 0.9,   # r/stocks
            "reddit_investing": 1.0, # r/investing
            "stocktwits": 0.7,
            "twitter": 0.6,
            "discord": 0.5
        }
        
        # ì£¼ìš” ì„œë¸Œë ˆë”§
        self.stock_subreddits = [
            "wallstreetbets",
            "stocks", 
            "investing",
            "StockMarket",
            "SecurityAnalysis",
            "ValueInvesting",
            "options"
        ]
        
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.session = aiohttp.ClientSession()
        # Reddit ì¸ì¦
        if self.reddit_client_id and self.reddit_client_secret:
            await self._authenticate_reddit()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.session:
            await self.session.close()
            
    async def _authenticate_reddit(self):
        """Reddit OAuth ì¸ì¦"""
        auth = aiohttp.BasicAuth(self.reddit_client_id, self.reddit_client_secret)
        data = {
            'grant_type': 'client_credentials'
        }
        headers = {'User-Agent': 'StockAI/1.0'}
        
        async with self.session.post(
            'https://www.reddit.com/api/v1/access_token',
            auth=auth,
            data=data,
            headers=headers
        ) as response:
            if response.status == 200:
                result = await response.json()
                self.reddit_token = result['access_token']
                
    async def search_reddit(self,
                           query: str,
                           subreddit: Optional[str] = None,
                           sort: str = "relevance",
                           time_filter: str = "week",
                           limit: int = 25) -> Dict[str, Any]:
        """
        Reddit ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ì–´ (ì£¼ì‹ëª…, í‹°ì»¤)
            subreddit: íŠ¹ì • ì„œë¸Œë ˆë”§ (ì—†ìœ¼ë©´ ì£¼ì‹ ê´€ë ¨ ëª¨ë“  ì„œë¸Œë ˆë”§)
            sort: ì •ë ¬ ë°©ì‹ (relevance, hot, top, new)
            time_filter: ì‹œê°„ í•„í„° (day, week, month, year, all)
            limit: ê²°ê³¼ ìˆ˜
        """
        if not self.reddit_token:
            # ì¸ì¦ ì—†ì´ ëª¨ì˜ ë°ì´í„° ë°˜í™˜
            return await self._get_mock_reddit_data(query)
            
        headers = {
            'Authorization': f'Bearer {self.reddit_token}',
            'User-Agent': 'StockAI/1.0'
        }
        
        # ì„œë¸Œë ˆë”§ ì§€ì •
        if subreddit:
            search_url = f"{self.reddit_base_url}/r/{subreddit}/search"
        else:
            # ì£¼ì‹ ê´€ë ¨ ì„œë¸Œë ˆë”§ ì „ì²´ ê²€ìƒ‰
            subreddit_str = "+".join(self.stock_subreddits)
            search_url = f"{self.reddit_base_url}/r/{subreddit_str}/search"
            
        params = {
            'q': query,
            'sort': sort,
            't': time_filter,
            'limit': limit,
            'restrict_sr': 'on'  # í•´ë‹¹ ì„œë¸Œë ˆë”§ìœ¼ë¡œ ì œí•œ
        }
        
        try:
            async with self.session.get(
                search_url,
                headers=headers,
                params=params
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    posts = []
                    for item in data.get('data', {}).get('children', []):
                        post_data = item['data']
                        
                        post = SocialPost(
                            content=f"{post_data.get('title', '')}\n{post_data.get('selftext', '')}",
                            author=post_data.get('author', 'unknown'),
                            platform=f"reddit_{post_data.get('subreddit', '').lower()}",
                            created_at=datetime.fromtimestamp(post_data.get('created_utc', 0)).isoformat(),
                            url=f"https://reddit.com{post_data.get('permalink', '')}",
                            score=post_data.get('score', 0),
                            comments=post_data.get('num_comments', 0)
                        )
                        posts.append(asdict(post))
                        
                    return {
                        "status": "success",
                        "platform": "reddit",
                        "count": len(posts),
                        "posts": posts,
                        "data_source": "REAL_DATA"
                    }
                else:
                    return {
                        "status": "error",
                        "message": f"HTTP error: {response.status}",
                        "data_source": "REAL_DATA"
                    }
                    
        except Exception as e:
            return {
                "status": "error",
                "message": f"Request failed: {str(e)}",
                "data_source": "REAL_DATA"
            }
            
    async def get_wsb_sentiment(self, ticker: str) -> Dict[str, Any]:
        """
        r/wallstreetbetsì—ì„œ íŠ¹ì • ì¢…ëª©ì˜ ê°ì„± ë¶„ì„
        
        Args:
            ticker: ì¢…ëª© í‹°ì»¤
        """
        # WSB íŠ¹í™” ê²€ìƒ‰
        result = await self.search_reddit(
            query=f"${ticker} OR {ticker}",
            subreddit="wallstreetbets",
            sort="hot",
            time_filter="day",
            limit=50
        )
        
        if result["status"] == "success":
            posts = result.get("posts", [])
            
            # ê°ì„± ë¶„ì„ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
            bullish_keywords = [
                "moon", "rocket", "buy", "calls", "bullish", "long",
                "ğŸš€", "ğŸ’", "ğŸ™Œ", "green", "up", "pump", "squeeze"
            ]
            bearish_keywords = [
                "puts", "short", "sell", "bearish", "crash", "dump",
                "ğŸ“‰", "ğŸ»", "red", "down", "overvalued", "bubble"
            ]
            
            sentiment_scores = []
            total_score = 0
            total_comments = 0
            
            for post in posts:
                content_lower = post['content'].lower()
                
                # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
                bullish_count = sum(1 for keyword in bullish_keywords if keyword in content_lower)
                bearish_count = sum(1 for keyword in bearish_keywords if keyword in content_lower)
                
                # ê°œë³„ í¬ìŠ¤íŠ¸ ê°ì„± ì ìˆ˜
                if bullish_count > bearish_count:
                    sentiment = min(1.0, bullish_count * 0.2)
                elif bearish_count > bullish_count:
                    sentiment = max(-1.0, -bearish_count * 0.2)
                else:
                    sentiment = 0.0
                    
                # ì ìˆ˜ì™€ ëŒ“ê¸€ ìˆ˜ë¡œ ê°€ì¤‘ì¹˜ ì ìš©
                weight = 1 + (post['score'] / 100) + (post['comments'] / 50)
                sentiment_scores.append(sentiment * weight)
                
                total_score += post['score']
                total_comments += post['comments']
                
            # ì „ì²´ ê°ì„± ì ìˆ˜ ê³„ì‚°
            if sentiment_scores:
                avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
            else:
                avg_sentiment = 0.0
                
            return {
                "status": "success",
                "ticker": ticker,
                "platform": "reddit_wallstreetbets",
                "post_count": len(posts),
                "total_score": total_score,
                "total_comments": total_comments,
                "sentiment_score": round(avg_sentiment, 2),
                "sentiment_label": self._get_sentiment_label(avg_sentiment),
                "top_posts": posts[:5],  # ìƒìœ„ 5ê°œ í¬ìŠ¤íŠ¸
                "data_source": result.get("data_source", "REAL_DATA")
            }
        else:
            return result
            
    async def search_stocktwits(self, ticker: str) -> Dict[str, Any]:
        """
        StockTwitsì—ì„œ ì¢…ëª© ê²€ìƒ‰ (ëª¨ì˜ ë°ì´í„°)
        
        Args:
            ticker: ì¢…ëª© í‹°ì»¤
        """
        # StockTwits APIëŠ” ì¸ì¦ì´ í•„ìš”í•˜ë¯€ë¡œ ëª¨ì˜ ë°ì´í„° ë°˜í™˜
        mock_posts = [
            {
                "content": f"âš ï¸ ëª¨ì˜ ë°ì´í„° - StockTwits API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\n${ticker} ìƒìŠ¹ ëª¨ë©˜í…€ ê°•í•˜ê²Œ ë³´ì„! $150 ì €í•­ì„  ëŒíŒŒ ğŸš€",
                "author": "trader123",
                "platform": "stocktwits",
                "created_at": datetime.now().isoformat(),
                "url": f"https://stocktwits.com/symbol/{ticker}",
                "score": 45,
                "comments": 12,
                "sentiment": 0.7
            },
            {
                "content": f"âš ï¸ ëª¨ì˜ ë°ì´í„° - StockTwits API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\n${ticker} RSI ê³¼ë§¤ìˆ˜ ìƒíƒœ, ì¡°ì • ì˜ˆìƒ",
                "author": "technicaltrader",
                "platform": "stocktwits", 
                "created_at": (datetime.now() - timedelta(hours=2)).isoformat(),
                "url": f"https://stocktwits.com/symbol/{ticker}",
                "score": 23,
                "comments": 5,
                "sentiment": -0.3
            }
        ]
        
        return {
            "status": "success",
            "platform": "stocktwits",
            "ticker": ticker,
            "count": len(mock_posts),
            "posts": mock_posts,
            "data_source": "MOCK_DATA"
        }
        
    async def get_trending_tickers(self, platform: str = "all") -> Dict[str, Any]:
        """
        íŠ¸ë Œë”© ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        
        Args:
            platform: í”Œë«í¼ (reddit, stocktwits, all)
        """
        trending = {
            "reddit": [
                {"ticker": "GME", "mentions": 1523, "sentiment": 0.6},
                {"ticker": "AMC", "mentions": 892, "sentiment": 0.4},
                {"ticker": "TSLA", "mentions": 756, "sentiment": 0.2},
                {"ticker": "NVDA", "mentions": 623, "sentiment": 0.8},
                {"ticker": "SPY", "mentions": 412, "sentiment": -0.1}
            ],
            "stocktwits": [
                {"ticker": "AAPL", "mentions": 2341, "sentiment": 0.5},
                {"ticker": "TSLA", "mentions": 1876, "sentiment": 0.3},
                {"ticker": "AMD", "mentions": 1234, "sentiment": 0.7},
                {"ticker": "MSFT", "mentions": 987, "sentiment": 0.4},
                {"ticker": "META", "mentions": 765, "sentiment": 0.2}
            ]
        }
        
        if platform == "all":
            # ëª¨ë“  í”Œë«í¼ í†µí•©
            all_tickers = {}
            for plat, tickers in trending.items():
                for item in tickers:
                    ticker = item["ticker"]
                    if ticker not in all_tickers:
                        all_tickers[ticker] = {
                            "mentions": 0,
                            "sentiment_sum": 0,
                            "platforms": []
                        }
                    all_tickers[ticker]["mentions"] += item["mentions"]
                    all_tickers[ticker]["sentiment_sum"] += item["sentiment"] * item["mentions"]
                    all_tickers[ticker]["platforms"].append(plat)
                    
            # í‰ê·  ê°ì„± ê³„ì‚° ë° ì •ë ¬
            result = []
            for ticker, data in all_tickers.items():
                avg_sentiment = data["sentiment_sum"] / data["mentions"]
                result.append({
                    "ticker": ticker,
                    "total_mentions": data["mentions"],
                    "avg_sentiment": round(avg_sentiment, 2),
                    "platforms": data["platforms"]
                })
                
            result.sort(key=lambda x: x["total_mentions"], reverse=True)
            
            return {
                "status": "success",
                "platform": "all",
                "trending": result[:10],  # ìƒìœ„ 10ê°œ
                "data_source": "MOCK_DATA"
            }
        else:
            return {
                "status": "success", 
                "platform": platform,
                "trending": trending.get(platform, []),
                "data_source": "MOCK_DATA"
            }
            
    async def _get_mock_reddit_data(self, query: str) -> Dict[str, Any]:
        """Reddit API ì¸ì¦ ì—†ì´ ëª¨ì˜ ë°ì´í„° ë°˜í™˜"""
        mock_posts = [
            SocialPost(
                content=f"âš ï¸ ëª¨ì˜ ë°ì´í„° - Reddit API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\n{query} DD: ì´ ì£¼ì‹ì— ëŒ€í•œ ê°•ì„¸ ì „ë§ ğŸš€ğŸš€ğŸš€",
                author="WSBTrader123",
                platform="reddit_wallstreetbets",
                created_at=datetime.now().isoformat(),
                url="https://reddit.com/r/wallstreetbets/mock1",
                score=1523,
                comments=234,
                sentiment=0.8
            ),
            SocialPost(
                content=f"âš ï¸ ëª¨ì˜ ë°ì´í„° - Reddit API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\nê¸°ìˆ ì  ë¶„ì„: {query} ì»µì•¤í•¸ë“¤ íŒ¨í„´ í˜•ì„± ì¤‘",
                author="TechnicalTrader",
                platform="reddit_stocks",
                created_at=(datetime.now() - timedelta(hours=5)).isoformat(),
                url="https://reddit.com/r/stocks/mock2",
                score=456,
                comments=78,
                sentiment=0.5
            ),
            SocialPost(
                content=f"âš ï¸ ëª¨ì˜ ë°ì´í„° - Reddit API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\n{query} ì£¼ì˜ í•„ìš”, í˜„ì¬ ê°€ê²© ìˆ˜ì¤€ì—ì„œ ê³¼ëŒ€í‰ê°€ë¨",
                author="ValueInvestor",
                platform="reddit_investing",
                created_at=(datetime.now() - timedelta(days=1)).isoformat(),
                url="https://reddit.com/r/investing/mock3",
                score=234,
                comments=45,
                sentiment=-0.3
            )
        ]
        
        return {
            "status": "success",
            "message": "âš ï¸ ëª¨ì˜ ë°ì´í„° - Reddit API ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ",
            "platform": "reddit",
            "count": len(mock_posts),
            "posts": [asdict(post) for post in mock_posts],
            "data_source": "MOCK_DATA"
        }
        
    def _get_sentiment_label(self, score: float) -> str:
        """ê°ì„± ì ìˆ˜ë¥¼ ë¼ë²¨ë¡œ ë³€í™˜"""
        if score >= 0.6:
            return "Very Bullish ğŸš€"
        elif score >= 0.2:
            return "Bullish ğŸ“ˆ"
        elif score >= -0.2:
            return "Neutral â–"
        elif score >= -0.6:
            return "Bearish ğŸ“‰"
        else:
            return "Very Bearish ğŸ»"


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_social_agent():
    """Social Agent í…ŒìŠ¤íŠ¸"""
    print("=== Social Agent í…ŒìŠ¤íŠ¸ ===\\n")
    
    async with SocialAgent() as agent:
        # 1. Reddit ê²€ìƒ‰
        print("1. Redditì—ì„œ TSLA ê²€ìƒ‰")
        result = await agent.search_reddit("TSLA", limit=5)
        if result["status"] == "success":
            print(f"ê²€ìƒ‰ ê²°ê³¼: {result['count']}ê±´")
            for post in result.get("posts", [])[:3]:
                content_lines = post['content'].split('\n')
                print("")
                print(f"ì œëª©: {content_lines[0][:80]}...")
                print(f"ì‘ì„±ì: {post['author']}")
                print(f"ì ìˆ˜: {post['score']}, ëŒ“ê¸€: {post['comments']}")
                
        print("\n" + "-" * 50 + "\n")
        
        # 2. WSB ê°ì„± ë¶„ì„
        print("2. r/wallstreetbets GME ê°ì„± ë¶„ì„")
        result = await agent.get_wsb_sentiment("GME")
        if result["status"] == "success":
            print(f"ë¶„ì„ í¬ìŠ¤íŠ¸ ìˆ˜: {result['post_count']}")
            print(f"ì´ ì ìˆ˜: {result['total_score']}")
            print(f"ì´ ëŒ“ê¸€: {result['total_comments']}")
            print(f"ê°ì„± ì ìˆ˜: {result['sentiment_score']} ({result['sentiment_label']})")
            
        print("\n" + "-" * 50 + "\n")
        
        # 3. StockTwits ê²€ìƒ‰
        print("3. StockTwits AAPL ê²€ìƒ‰")
        result = await agent.search_stocktwits("AAPL")
        if result["status"] == "success":
            print(f"ê²€ìƒ‰ ê²°ê³¼: {result['count']}ê±´")
            for post in result.get("posts", []):
                print(f"- {post['content']}")
                print(f"  ê°ì„±: {post['sentiment']}")
                
        print("\n" + "-" * 50 + "\n")
        
        # 4. íŠ¸ë Œë”© ì¢…ëª©
        print("4. ì „ì²´ í”Œë«í¼ íŠ¸ë Œë”© ì¢…ëª©")
        result = await agent.get_trending_tickers("all")
        if result["status"] == "success":
            print("Top 5 íŠ¸ë Œë”© ì¢…ëª©:")
            for item in result["trending"][:5]:
                print(f"- {item['ticker']}: {item['total_mentions']}íšŒ ì–¸ê¸‰")
                print(f"  í‰ê·  ê°ì„±: {item['avg_sentiment']}")
                print(f"  í”Œë«í¼: {', '.join(item['platforms'])}")
                

if __name__ == "__main__":
    asyncio.run(test_social_agent())